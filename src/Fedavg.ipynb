{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63ec897f-c5fc-4164-9d52-da3ddf25347b",
   "metadata": {},
   "source": [
    "# FedAvg Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4e8391a-789a-4747-96a9-5a3b8fb7c443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/bin/python\n"
     ]
    }
   ],
   "source": [
    "#@test {\"skip\": true}\n",
    "\n",
    "!which python\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import sys\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214b403d-8b9c-4c9f-a9f1-38575a2ae9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import collections\n",
    "\n",
    "from IPython.display import display, HTML, IFrame\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "\n",
    "print(tff.__version__)\n",
    "\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "np.random.seed(0)\n",
    "#def greetings():\n",
    "#  display(HTML('<b><font size=\"6\" color=\"#ff00f4\">Greetings, virtual tutorial participants!</font></b>'))\n",
    "#  return True\n",
    "#l = tff.federated_computation(greetings)()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bb80f2-4c0e-418b-80c6-8f6dc26ba84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for loading federated data from TFF repository\n",
    "emnist_train, emnist_test = tff.simulation.datasets.emnist.load_data(only_digits=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b6bc93-88f5-477c-b845-33986bccdca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(emnist_train.client_ids), len(emnist_test.client_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b3b40e-d2a7-40de-a245-5253f07e0cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the shape of our data\n",
    "example_dataset = emnist_train.create_tf_dataset_for_client(\n",
    "    emnist_train.client_ids[0])\n",
    "#example_dataset\n",
    "example_dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520d3811-05c8-45f5-b139-7bef0f03c1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's select an example dataset from one of our simulated clients\n",
    "example_dataset = emnist_train.create_tf_dataset_for_client(\n",
    "    emnist_train.client_ids[45])\n",
    "\n",
    "# Your code to get an example element from one client:\n",
    "example_element = next(iter(example_dataset))\n",
    "\n",
    "example_element['label'].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3ccef3-6162-4c83-aafb-8aefba4d5ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(example_element['pixels'].numpy(), cmap='gray', aspect='equal')\n",
    "plt.grid(False)\n",
    "_ = plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d987fdcf-81e1-4e00-9812-07872ec4c9ea",
   "metadata": {},
   "source": [
    "**Exploring non-iid data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13ea3bb-9ac7-4499-9d68-d1701bdb8306",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example MNIST digits for one client\n",
    "f = plt.figure(figsize=(20,4))\n",
    "j = 0\n",
    "\n",
    "for e in example_dataset.take(40):\n",
    "  plt.subplot(4, 10, j+1)\n",
    "  plt.imshow(e['pixels'].numpy(), cmap='gray', aspect='equal')\n",
    "  plt.axis('off')\n",
    "  j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2523fa08-e283-4fa0-ac91-2bdfdbcb07d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of examples per layer for a sample of clients\n",
    "f = plt.figure(figsize=(12,7))\n",
    "f.suptitle(\"Label Counts for a Sample of Clients\")\n",
    "for i in range(6):\n",
    "  ds = emnist_train.create_tf_dataset_for_client(emnist_train.client_ids[i])\n",
    "  k = collections.defaultdict(list)\n",
    "  for e in ds:\n",
    "    k[e['label'].numpy()].append(e['label'].numpy())\n",
    "  plt.subplot(2, 3, i+1)\n",
    "  plt.title(\"Client {}\".format(i))\n",
    "  for j in range(62):\n",
    "    plt.hist(k[j], density=False, bins=[i for i in range(62)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf49732f-55e2-433c-a89f-e153c1b1c849",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2,5):\n",
    "  ds = emnist_train.create_tf_dataset_for_client(emnist_train.client_ids[i])\n",
    "  k = collections.defaultdict(list)\n",
    "  for e in ds:\n",
    "    k[e['label'].numpy()].append(e['pixels'].numpy())\n",
    "  f = plt.figure(i, figsize=(12,10))\n",
    "  f.suptitle(\"Client #{}'s Mean Image Per Label\".format(i))\n",
    "  for j in range(20):\n",
    "    mn_img = np.mean(k[j],0)\n",
    "    plt.subplot(2, 10, j+1)\n",
    "    if (mn_img.size==1):\n",
    "      continue\n",
    "    plt.imshow(mn_img.reshape((28,28)))#,cmap='gray') \n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16840acd-6547-40a3-89af-d56fd5a98b44",
   "metadata": {},
   "source": [
    "### Preprocessing the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddaa7d29-cff4-4900-8008-fbecf756a68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLIENTS = 20\n",
    "NUM_EPOCHS = 1\n",
    "BATCH_SIZE = 20\n",
    "SHUFFLE_BUFFER = 100\n",
    "PREFETCH_BUFFER=10\n",
    "\n",
    "def preprocess(dataset):\n",
    "\n",
    "  def batch_format_fn(element):\n",
    "    \"\"\"Flatten a batch `pixels` and return the features as an `OrderedDict`.\"\"\"\n",
    "    return collections.OrderedDict(\n",
    "        x=tf.reshape(element['pixels'], [-1, 28,28,1]),\n",
    "        y=tf.reshape(element['label'], [-1, 1]))\n",
    "\n",
    "  return dataset.repeat(NUM_EPOCHS).shuffle(SHUFFLE_BUFFER).batch(\n",
    "      BATCH_SIZE).map(batch_format_fn).prefetch(PREFETCH_BUFFER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c116d057-6304-4a63-9ff4-b3f136b68193",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_example_dataset = preprocess(example_dataset)\n",
    "\n",
    "sample_batch = tf.nest.map_structure(lambda x: x.numpy(),\n",
    "                                     next(iter(preprocessed_example_dataset)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060b275e-d550-47fa-8c1d-898696f6fcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_federated_data(client_data, client_ids):\n",
    "  return [\n",
    "      preprocess(client_data.create_tf_dataset_for_client(x))\n",
    "      for x in client_ids\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684eac85-86fc-4a91-bb48-2067d4431282",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "shuffled_ids = emnist_train.client_ids.copy()\n",
    "random.shuffle(shuffled_ids)\n",
    "shuffled_ids_train = shuffled_ids[0:2500]\n",
    "sample_clients = shuffled_ids_train[0:NUM_CLIENTS]\n",
    "\n",
    "# Your code to get the federated dataset here for the sampled clients:\n",
    "\n",
    "federated_train_data = make_federated_data(emnist_train, sample_clients)\n",
    "\n",
    "print('Number of client datasets: {l}'.format(l=len(federated_train_data)))\n",
    "print('First dataset: {d}'.format(d=federated_train_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170bc366-35c5-40c9-8fdb-01b7eb190326",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a model with Keras\n",
    "\n",
    "If you are using Keras, you likely already have code that constructs a Keras\n",
    "model. Here's an example of a simple model that will suffice for our needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f639e1ef-1fb4-42ed-8aa1-e19e07bcc38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_keras_model():\n",
    "    \n",
    "  data_format = 'channels_last'\n",
    "  initializer = tf.keras.initializers.RandomNormal(seed=0)\n",
    "  return tf.keras.models.Sequential([\n",
    "      tf.keras.layers.Input(shape=(28, 28,1)),\n",
    "      tf.keras.layers.Conv2D(32,(3,3), activation='relu'),\n",
    "      tf.keras.layers.Conv2D(64,(3,3), activation='relu'),\n",
    "      tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2)),\n",
    "      tf.keras.layers.Dropout(rate=0.75),\n",
    "      tf.keras.layers.Flatten(),\n",
    "      tf.keras.layers.Dense(128, activation='relu', kernel_initializer=initializer),\n",
    "      tf.keras.layers.Dropout(rate=0.5, seed=1),\n",
    "      tf.keras.layers.Dense(62, kernel_initializer=initializer),\n",
    "      tf.keras.layers.Softmax()\n",
    "  ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c9e192-c6bf-4dcb-aaae-d86e6c5be4a6",
   "metadata": {},
   "source": [
    "## Centralized training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a108b94-0aa1-4c37-8f2e-97b24b71e860",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Centralized training with keras ---------------------------------------------\n",
    "\n",
    "# This is separate from the TFF tutorial, and demonstrates how to train a\n",
    "# Keras model in a centralized fashion (contrasting training in a federated env)\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Preprocess the data (these are NumPy arrays)\n",
    "x_train = x_train.reshape(60000, 28,28,1).astype(\"float32\") / 255\n",
    "\n",
    "y_train = y_train.astype(\"float32\")\n",
    "\n",
    "mod = create_keras_model()\n",
    "mod.compile(\n",
    "    optimizer=tf.keras.optimizers.RMSprop(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    ")\n",
    "h = mod.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=64,\n",
    "    epochs=2\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23becc7b-db70-42f4-b0f4-4bc7d39fad47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn():\n",
    "  # We _must_ create a new model here, and _not_ capture it from an external\n",
    "  # scope. TFF will call this within different graph contexts.\n",
    "  keras_model = create_keras_model()\n",
    "  return tff.learning.from_keras_model(\n",
    "      keras_model,\n",
    "      input_spec=preprocessed_example_dataset.element_spec,\n",
    "      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6157b721-1db7-4bd5-a300-45c2bdd6716d",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterative_process = tff.learning.build_federated_averaging_process(\n",
    "    model_fn,\n",
    "    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.05),\n",
    "    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0, momentum=0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb48d0c6-9263-48fc-ba08-cc39070c9aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = iterative_process.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccbb1b0-9fd4-4726-a21a-babf30337d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run one single round of training.\n",
    "state, metrics = iterative_process.next(state, federated_train_data)\n",
    "print('round  1, metrics={}'.format(metrics['train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db731acd-9191-4763-96ca-505f51434cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ROUNDS = 1000\n",
    "for round_num in range(2, NUM_ROUNDS):\n",
    "  state, metrics = iterative_process.next(state, federated_train_data)\n",
    "  print('round {:2d}, metrics={}'.format(round_num, metrics['train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1418e71a-6af1-4b04-b2ea-df0406c2cbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@test {\"skip\": true}\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "logdir = \"/tmp/logs/scalars/training/\"\n",
    "if os.path.exists(logdir):\n",
    "  shutil.rmtree(logdir)\n",
    "\n",
    "# Your code to create a summary writer:\n",
    "summary_writer = tf.summary.create_file_writer(logdir)\n",
    "\n",
    "state = iterative_process.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fcf321-4e2d-4339-a569-b9924f3eb7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@test {\"skip\": true}\n",
    "with summary_writer.as_default():\n",
    "  for round_num in range(1, NUM_ROUNDS):\n",
    "    state, metrics = iterative_process.next(state, federated_train_data)\n",
    "    print('round {:2d}, metrics={}'.format(round_num, metrics['train']))\n",
    "    for name, value in metrics['train'].items():\n",
    "      tf.summary.scalar(name, value, step=round_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be49e554-7970-46dc-ba9e-9e9285f23e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@test {\"skip\": true}\n",
    "%tensorboard --logdir /tmp/logs/scalars/ --port=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa7ce94-f56c-4fbb-b197-752f41099055",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de52260-c4f0-4fcf-9dba-f616fa255418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct federated evaluation computation here:\n",
    "evaluation = tff.learning.build_federated_evaluation(model_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3b95f6-1306-4491-ba0b-9f1845b450e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "shuffled_ids = emnist_test.client_ids.copy()\n",
    "random.shuffle(shuffled_ids)\n",
    "sample_clients = shuffled_ids[0:NUM_CLIENTS]\n",
    "\n",
    "federated_test_data = make_federated_data(emnist_test, sample_clients)\n",
    "\n",
    "len(federated_test_data), federated_test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18aa3fc-aa69-451c-8acc-aef70a0020e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run evaluation on the test data here, using the federated model produced from \n",
    "# training:\n",
    "test_metrics = evaluation(state.model, federated_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba81fe7-f82d-47fd-bca2-a071f97471ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "str(test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bbce4e-ec7b-4c2b-939c-61465566cdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_manager = tff.simulation.FileCheckpointManager(root_dir=\"/src/training/\")\n",
    "ckpt_manager.save_checkpoint(tff.learning.framework.ServerState(state.model,state,None,None), round_num=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
